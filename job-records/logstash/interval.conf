
input { stdin { } }


output {
    if !("_grokparsefailure" in [tags]) {
        elasticsearch {
            protocol => "http"
            host => "uct2-es-door.mwt2.org"
            index => "interval_data_%{+GGGG-WW}"
            index_type => "interval_record"
            cluster => "dataanalytics"

        }
#        stdout { codec => rubydebug }
    }
#    if ("_grokparsefailure" in [tags]) {
#        stdout { codec => json }
#    }
}





filter {
    grok {
        match => { "message" => "%{INT:CRTIME:int} %{INT:PANDAID:int} %{WORD:CLOUD} %{WORD:COMPUTINGSITE} %{WORD:PRODSOURCELABEL} %{DATA:raw_times} %{INT:SKIPPED:int} %{INT:SORTED:int}"}

    }
    # strip fields of whitespace
    mutate {
        strip => [ "CLOUD", "COMPUTINGSITE", "PRODSOURCELABEL" ]
    }

    # create times field with json
    if [raw_times] {
        ruby {
            code => "items = event['raw_times'][1..-2]; json = ''; for item in items.split("/\(\w+,\d+\)/"); if (item =~ /\((\w+),(\d+)\)/); state = $1; time = $2; json += \"\n{'state': '#{state}', 'time': '#{time}'},\"; end; end; json = '{' + json[1..] + '}'; event['json_times'] = json"
            remove_field => [ "raw_times" ]
        }
    }

    if [json_times] {
        json {
            source => "json_times"
            target => "times"
            remove_field => [ "json_times" ]
        }
    }

    # set timestamp
    date {
        match => ["CRTIME", "UNIX_MS" ]
    }



}


